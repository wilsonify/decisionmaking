struct SMILe
    """
    The SMILe algorithm for training a stochastic parameterized policy from expert demonstrations for an MDP ğ’« .
SMILe successively mixes in new
component policies with smaller
and smaller weight, while simultaneously reducing the probability of
acting according to the expert policy. The method returns the probabilities Ps and parameterizations
Î¸s for the component policies.
    """

    ğ’«::Any # problem with unknown reward
    bc::Any     # Behavioral cloning struct
    k_max::Any # number of iterations
    m::Any     # number of rollouts per iteration
    d::Any     # rollout depth
    b::Any    # initial state distribution
    Î²::Any    # mixing scalar (e.g., d^-3)
    Ï€E::Any    # expert policy
    Ï€Î¸::Any    # parameterized policy
end
function optimize(M::SMILe, Î¸)
    ğ’«, bc, k_max, m = M.ğ’«, M.bc, M.k_max, M.m
    d, b, Î², Ï€E, Ï€Î¸ = M.d, M.b, M.Î², M.Ï€E, M.Ï€Î¸
    ğ’œ, T = ğ’«.ğ’œ, ğ’«.T
    Î¸s = []
    Ï€ = s -> Ï€E(s)
    for k = 1:k_max
        # execute latest Ï€ to get new dataset D
        D = []
        for i = 1:m
            s = rand(b)
            for j = 1:d
                push!(D, (s, Ï€E(s)))
                a = Ï€(s)
                s = rand(T(s, a))
            end
        end
        # train new policy classifier
        Î¸ = optimize(bc, D, Î¸)
        push!(Î¸s, Î¸)
        # compute a new policy mixture
        PÏ€ = Categorical(normalize([(1 - Î²)^(i - 1) for i = 1:k], 1))
        Ï€ = s -> begin
            if rand() < (1 - Î²)^(k - 1)
                return Ï€E(s)
            else
                return rand(Categorical(Ï€Î¸(Î¸s[rand(PÏ€)], s)))
            end
        end
    end
    Ps = normalize([(1 - Î²)^(i - 1) for i = 1:k_max], 1)
    return Ps, Î¸s
end
