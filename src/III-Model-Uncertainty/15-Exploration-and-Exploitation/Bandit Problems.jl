struct BanditProblem
    """
    Simulation of a bandit problem. 
    A bandit problem is defined by a vector θ of payoff probabilities, one per action. 
    We also define a function R that simulates the generation of a stochastic binary reward in response to the selection of an action. 
    Each step of a simulation involves generating an action a from the exploration policy π . 
    The exploration policy generally consults the model in the selection of the action. 
    The selection of that action results in a randomly generated reward, which is then used to update the model. 
    Simulations are run to horizon h .
    """
    θ::Any # vector of payoff probabilities
    R::Any # reward sampler
end

function simulate(problem::BanditProblem, model, π, h)
    """
    generate an action from the exploration policy π.
    consult the model.
    generate reward.
    update the model. 
    run to horizon h.
    """
    for i = 1:h
        a = π(model)
        r = problem.R(a)
        update!(model, a, r)
    end
end

function bandito(θ)
    """
    Construct BanditProblem with random uniform reward sampler
    """
    R(a) = rand() < θ[a] ? 1 : 0
    return BanditProblem(θ, R)
end

