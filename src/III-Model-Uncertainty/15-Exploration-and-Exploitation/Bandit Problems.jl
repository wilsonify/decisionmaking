struct BanditProblem
    """
    Simulation of a
bandit problem. A bandit problem
is defined by a vector Î¸ of payoff
probabilities, one per action. We
also define a function R that simulates the generation of a stochastic
binary reward in response to the selection of an action. Each step of a
simulation involves generating an
action a from the exploration policy Ï€ . The exploration policy generally consults the model in the selection of the action. The selection of
that action results in a randomly
generated reward, which is then
used to update the model. Simulations are run to horizon h .
    """
    Î¸ # vector of payoff probabilities
    R # reward sampler
    end
    function BanditProblem(Î¸)
    R(a) = rand() < Î¸[a] ? 1 : 0
    return BanditProblem(Î¸, R)
    end
    function simulate(ð’«::BanditProblem, model, Ï€, h)
    for i in 1:h
    a = Ï€(model)
    r = ð’«.R(a)
    update!(model, a, r)
    end
    end