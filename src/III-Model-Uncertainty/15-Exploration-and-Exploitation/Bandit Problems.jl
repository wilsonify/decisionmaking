struct BanditProblem
    """
    Simulation of a
bandit problem. A bandit problem
is defined by a vector θ of payoff
probabilities, one per action. We
also define a function R that simulates the generation of a stochastic
binary reward in response to the selection of an action. Each step of a
simulation involves generating an
action a from the exploration policy π . The exploration policy generally consults the model in the selection of the action. The selection of
that action results in a randomly
generated reward, which is then
used to update the model. Simulations are run to horizon h .
    """
    θ # vector of payoff probabilities
    R # reward sampler
    end
    function BanditProblem(θ)
    R(a) = rand() < θ[a] ? 1 : 0
    return BanditProblem(θ, R)
    end
    function simulate(𝒫::BanditProblem, model, π, h)
    for i in 1:h
    a = π(model)
    r = 𝒫.R(a)
    update!(model, a, r)
    end
    end