
"""
The Q-learning update for model-free reinforcement learning, 
which can be applied to problems with unknown transition and reward functions.
The update modifies Q, which is a matrix of state-action values. 
This update function can be used together with an exploration strategy,
such as Ç«-greedy in the simulate function in simulate.
"""
mutable struct QLearning
    ğ’®::Any # state space (assumes 1:nstates)
    ğ’œ::Any # action space (assumes 1:nactions)
    Î³::Any # discount
    Q::Any # action value function
    Î±::Any # learning rate
end


lookahead(model::QLearning, s, a) = model.Q[s, a]
function update!(model::QLearning, s, a, r, sâ€²)
    Î³, Q, Î± = model.Î³, model.Q, model.Î±
    Q[s, a] += Î± * (r + Î³ * maximum(Q[sâ€², :]) - Q[s, a])
    return model
end


