""" The Sarsa ( Î» ) update, which uses eligibility traces to
propagate reward back in time to
speed learning of sparse rewards.
The matrix Q contains the stateaction values, the matrix N contains exponentially decaying stateaction visit counts, Î± is a constant
learning rate, Î» is an exponential
decay parameter, and â„“ is the most
recent experience tuple.
"""
mutable struct SarsaLambda
    ğ’®::Any # state space (assumes 1:nstates)
    ğ’œ::Any # action space (assumes 1:nactions)
    Î³::Any # discount
    Q::Any # action value function
    N::Any # trace
    Î±::Any # learning rate
    Î»::Any # trace decay rate
    â„“::Any # most recent experience tuple (s,a,r)
end

lookahead(model::SarsaLambda, s, a) = model.Q[s, a]

function update!(model::SarsaLambda, s, a, r, sâ€²)
    if model.â„“ != nothing
        Î³, Î», Q, Î±, â„“ = model.Î³, model.Î», model.Q, model.Î±, model.â„“
        model.N[â„“.s, â„“.a] += 1
        Î´ = â„“.r + Î³ * Q[s, a] - Q[â„“.s, â„“.a]
        for s in model.ğ’®
            for a in model.ğ’œ
                model.Q[s, a] += Î± * Î´ * model.N[s, a]
                model.N[s, a] *= Î³ * Î»
            end
        end
    else
        model.N[:, :] .= 0.0
    end
    model.â„“ = (s = s, a = a, r = r)
    return model
end
