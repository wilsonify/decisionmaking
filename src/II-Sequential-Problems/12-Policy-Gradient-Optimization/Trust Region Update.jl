struct TrustRegionUpdate
    """
    The update pro-
cedure for trust region policy opti-
mization, which augments the nat-
ural gradient with a line search. It
generates m trajectories using pol-
icy Ï€ in problem ğ’« with initial state
distribution b and depth d . To ob-
tain the starting point of the line
search, we need the gradient of
the log-probability of the policy
generating a particular action from
the current state, which we denote
âˆ‡logÏ€ . For the surrogate objective,
we need the probability function p
that gives the probability our pol-
icy generates a particular action
from the current state. For the sur-
rogate constraint, we need the di-
vergence between the action distri-
butions generated by Ï€ Î¸ and Ï€ Î¸ â€² .
At each step of the line search, we
shrink the distance between the
considered point Î¸â€² and Î¸ while
maintaining the search direction.
    """

    ğ’«::Any # problem
    b::Any # initial state distribution
    d::Any # depth
    m::Any # number of samples
    Ï€::Any # policy Ï€(s)
    p::Any # policy likelihood p(Î¸, a, s)
    âˆ‡logÏ€::Any # log likelihood gradient
    KL::Any # KL divergence KL(Î¸, Î¸â€², s)
    Ïµ::Any # divergence bound
    Î±::Any # line search reduction factor (e.g. 0.5)
end
function surrogate_objective(M::TrustRegionUpdate, Î¸, Î¸â€², Ï„s)
    d, p, Î³ = M.d, M.p, M.ğ’«.Î³
    R(Ï„, j) = sum(r * Î³^(k - 1) for (k, (s, a, r)) in zip(j:d, Ï„[j:end]))
    w(a, s) = p(Î¸â€², a, s) / p(Î¸, a, s)
    f(Ï„) = mean(w(a, s) * R(Ï„, k) for (k, (s, a, r)) in enumerate(Ï„))
    return mean(f(Ï„) for Ï„ in Ï„s)
end
function surrogate_constraint(M::TrustRegionUpdate, Î¸, Î¸â€², Ï„s)
    Î³ = M.ğ’«.Î³
    KL(Ï„) = mean(M.KL(Î¸, Î¸â€², s) * Î³^(k - 1) for (k, (s, a, r)) in enumerate(Ï„))
    return mean(KL(Ï„) for Ï„ in Ï„s)
end

function linesearch(M::TrustRegionUpdate, f, g, Î¸, Î¸â€²)
    fÎ¸ = f(Î¸)
    while g(Î¸â€²) > M.Ïµ || f(Î¸â€²) â‰¤ fÎ¸
        Î¸â€² = Î¸ + M.Î± * (Î¸â€² - Î¸)
    end
    return Î¸â€²
end
function update(M::TrustRegionUpdate, Î¸)
    ğ’«, b, d, m, âˆ‡logÏ€, Ï€, Î³ = M.ğ’«, M.b, M.d, M.m, M.âˆ‡logÏ€, M.Ï€, M.ğ’«.Î³
    Ï€Î¸(s) = Ï€(Î¸, s)
    R(Ï„) = sum(r * Î³^(k - 1) for (k, (s, a, r)) in enumerate(Ï„))
    âˆ‡log(Ï„) = sum(âˆ‡logÏ€(Î¸, a, s) for (s, a) in Ï„)
    âˆ‡U(Ï„) = âˆ‡log(Ï„) * R(Ï„)
    F(Ï„) = âˆ‡log(Ï„) * âˆ‡log(Ï„)'
    Ï„s = [simulate(ğ’«, rand(b), Ï€Î¸, d) for i = 1:m]
    Î¸â€² = natural_update(Î¸, âˆ‡U, F, M.Ïµ, Ï„s)
    f(Î¸â€²) = surrogate_objective(M, Î¸, Î¸â€², Ï„s)
    g(Î¸â€²) = surrogate_constraint(M, Î¸, Î¸â€², Ï„s)
    return linesearch(M, f, g, Î¸, Î¸â€²)
end
