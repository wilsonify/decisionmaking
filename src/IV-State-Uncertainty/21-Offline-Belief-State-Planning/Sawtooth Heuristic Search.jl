
struct SawtoothHeuristicSearch
    """
    The sawtooth
    heuristic search policy. The solver
    starts from belief b and explores to
    a depth d for no more than k_max
    iterations. It uses an upper bound
    obtained through the fast informed
    bound computed with k_fib iterations.
    The lower bound is obtained from the best-action worststate bound. The gap threshold is
    Î´ .
    """

    b::Any # initial belief
    Î´::Any # gap threshold
    d::Any # depth
    k_max::Any # maximum number of iterations
    k_fib::Any # number of iterations for fast informed bound
end
function explore!(M::SawtoothHeuristicSearch, problem, Ï€hi, Ï€lo, b, d = 0)
    ð’®, ð’œ, ð’ª, Î³ = problem.ð’®, problem.ð’œ, problem.ð’ª, problem.Î³
    Ïµ(bâ€²) = utility(Ï€hi, bâ€²) - utility(Ï€lo, bâ€²)
    if d â‰¥ M.d || Ïµ(b) â‰¤ M.Î´ / Î³^d
        return
    end
    a = Ï€hi(b)
    o = argmax(o -> Ïµ(update(b, problem, a, o)), ð’ª)
    bâ€² = update(b, problem, a, o)
    explore!(M, problem, Ï€hi, Ï€lo, bâ€², d + 1)
    if bâ€² âˆ‰ basis(problem)
        Ï€hi.V[bâ€²] = greedy(Ï€hi, bâ€²).u
    end
    push!(Ï€lo.Î“, backup(problem, Ï€lo.Î“, bâ€²))
end

function solve(M::SawtoothHeuristicSearch, problem::POMDP)
    Ï€fib = solve(FastInformedBound(M.k_fib), problem)
    Vhi = Dict(e => utility(Ï€fib, e) for e in basis(problem))
    Ï€hi = SawtoothPolicy(problem, Vhi)
    Ï€lo = LookaheadAlphaVectorPolicy(problem, [baws_lowerbound(problem)])
    for i = 1:M.k_max
        explore!(M, problem, Ï€hi, Ï€lo, M.b)
        if utility(Ï€hi, M.b) - utility(Ï€lo, M.b) < M.Î´
            break
        end
    end
    return Ï€lo
end
