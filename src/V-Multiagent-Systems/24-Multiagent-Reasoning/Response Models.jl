include("Simple Games.jl")
struct SimpleGamePolicy
    """
    A policy associated with an agent is represented
    by a dictionary that maps actions
    to probabilities. There are different ways to construct a policy. One
    way is to pass in a dictionary directory, in which case the probabilities
    are normalized. Another way is to
    pass in a generator that creates this
    dictionary. We can also construct a
    policy by passing in an action, in
    which case it assigns probability 1
    to that action. If we have an individual policy Ï€i , we can call Ï€i(ai)
    to compute the probability the policy associates with action ai . If we
    call Ï€i() , then it will return a random action according to that policy.
    We can use joint(ğ’œ) to construct
    the joint action space from ğ’œ . We
    can use utility(ğ’«, Ï€, i) to compute the utility associated with executing joint policy Ï€ in the game
    ğ’« from the perspective of agent i .
    """
    p::Any # dictionary mapping actions to probabilities
    function SimpleGamePolicy(p::Base.Generator)
        return SimpleGamePolicy(Dict(p))
    end
    function SimpleGamePolicy(p::Dict)
        vs = collect(values(p))
        vs ./= sum(vs)
        return new(Dict(k => v for (k, v) in zip(keys(p), vs)))
    end
end
SimpleGamePolicy(ai) = new(Dict(ai => 1.0))
(Ï€i::SimpleGamePolicy)(ai) = get(Ï€i.p, ai, 0.0)
function (Ï€i::SimpleGamePolicy)()
    D = SetCategorical(collect(keys(Ï€i.p)), collect(values(Ï€i.p)))
    return rand(D)
end
joint(X) = vec(collect(product(X...)))
joint(Ï€, Ï€i, i) = [i == j ? Ï€i : Ï€j for (j, Ï€j) in enumerate(Ï€)]

function utility(ğ’«::SimpleGame, Ï€, i)
    ğ’œ, R = ğ’«.ğ’œ, ğ’«.R
    p(a) = prod(Ï€j(aj) for (Ï€j, aj) in zip(Ï€, a))
    return sum(R(a)[i] * p(a) for a in joint(ğ’œ))
end

"""
For a simple game
ğ’« , we can compute a deterministic best response for agent i given
that the other agents are playing
the policies in Ï€ .
"""
function best_response(ğ’«::SimpleGame, Ï€, i)
    U(ai) = utility(ğ’«, joint(Ï€, SimpleGamePolicy(ai), i), i)
    ai = argmax(U, ğ’«.ğ’œ[i])
    return SimpleGamePolicy(ai)
end
