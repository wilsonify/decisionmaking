struct BanditProblem
    """
    Simulation of a bandit problem. 
    A bandit problem is defined by a vector Œ∏ of payoff probabilities, one per action. 
    We also define a function R that simulates the generation of a stochastic binary reward in response to the selection of an action. 
    Each step of a simulation involves generating an action a from the exploration policy œÄ . 
    The exploration policy generally consults the model in the selection of the action. 
    The selection of that action results in a randomly generated reward, which is then used to update the model. 
    Simulations are run to horizon h .
    """
    Œ∏::Any # vector of payoff probabilities
    R::Any # reward sampler
end

function simulate(ùí´::BanditProblem, model, œÄ, h)
    """
    generate an action from the exploration policy œÄ.
    consult the model.
    generate reward.
    update the model. 
    run to horizon h.
    """
    for i = 1:h
        a = œÄ(model)
        r = ùí´.R(a)
        update!(model, a, r)
    end
end

function bandito(Œ∏)
    """
    Construct BanditProblem with random uniform reward sampler
    """
    R(a) = rand() < Œ∏[a] ? 1 : 0
    return BanditProblem(Œ∏, R)
end

