"""
A finite state controller policy representation for a
POMDP ğ’« . The nodes in X are an abstract representation of reachable
beliefs. Actions and controller successor nodes are selected stochastically. Given a node x , actions are selected following the distribution Ïˆ .
The function Ï€(x) implements this
mechanism to stochastically select
actions. After performing action a
in node x and observing observation o , the successor is selected following the distribution Î· . The function update implements this mechanism to stochastically select successor nodes.
"""
mutable struct ControllerPolicy
    ğ’«::Any # problem
    X::Any # set of controller nodes
    Ïˆ::Any # action selection distribution
    Î·::Any # successor selection distribution
end

function (Ï€::ControllerPolicy)(x)
    ğ’œ, Ïˆ = Ï€.ğ’«.ğ’œ, Ï€.Ïˆ
    dist = [Ïˆ[x, a] for a in ğ’œ]
    return rand(SetCategorical(ğ’œ, dist))
end
function update(Ï€::ControllerPolicy, x, a, o)
    X, Î· = Ï€.X, Ï€.Î·
    dist = [Î·[x, a, o, xâ€²] for xâ€² in X]
    return rand(SetCategorical(X, dist))
end


"""
An algorithm for
    performing iterative policy evaluation to compute the utility of a finite state controller Ï€ with k_max
    iterations. The utility function performs a single step evaluation for
    the current controller node x and
    state s following equation (23.1).
    This algorithm was adapted from
    algorithm 7.3, which applies iterative policy evaluation to MDPs.
"""
function utility(Ï€::ControllerPolicy, U, x, s)
    ğ’®, ğ’œ, ğ’ª = Ï€.ğ’«.ğ’®, Ï€.ğ’«.ğ’œ, Ï€.ğ’«.ğ’ª
    T, O, R, Î³ = Ï€.ğ’«.T, Ï€.ğ’«.O, Ï€.ğ’«.R, Ï€.ğ’«.Î³
    X, Ïˆ, Î· = Ï€.X, Ï€.Ïˆ, Ï€.Î·
    Uâ€²(a, sâ€², o) = sum(Î·[x, a, o, xâ€²] * U[xâ€², sâ€²] for xâ€² in X)
    Uâ€²(a, sâ€²) = T(s, a, sâ€²) * sum(O(a, sâ€², o) * Uâ€²(a, sâ€², o) for o in ğ’ª)
    Uâ€²(a) = R(s, a) + Î³ * sum(Uâ€²(a, sâ€²) for sâ€² in ğ’®)
    return sum(Ïˆ[x, a] * Uâ€²(a) for a in ğ’œ)
end
function iterative_policy_evaluation(Ï€::ControllerPolicy, k_max)
    ğ’®, X = Ï€.ğ’«.ğ’®, Ï€.X
    U = Dict((x, s) => 0.0 for x in X, s in ğ’®)
    for k = 1:k_max
        U = Dict((x, s) => utility(Ï€, U, x, s) for x in X, s in ğ’®)
    end
    return U
end
